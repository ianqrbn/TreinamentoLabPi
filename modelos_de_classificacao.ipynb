{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label                                           Mensagem  \\\n",
      "0      0  Go until jurong point, crazy.. Available only ...   \n",
      "1      0                      Ok lar... Joking wif u oni...   \n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3      0  U dun say so early hor... U c already then say...   \n",
      "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                              Mensagem_Preprocessada  \n",
      "0  go jurong point crazy available bugis n great ...  \n",
      "1                          ok lar joking wif you oni  \n",
      "2  free entry wkly comp win fa cup final tkts st ...  \n",
      "3            you dun say early hor you c already say  \n",
      "4         nah do not think go usf life around though  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def remover_caracteres_especiais(texto):\n",
    "    return re.sub(r'[^a-z\\s]', '', texto)\n",
    "\n",
    "def remover_stopwords(texto, stop_words):\n",
    "    palavras = nltk.word_tokenize(texto)\n",
    "    palavras_filtradas = [palavra for palavra in palavras if palavra.lower() not in stop_words]\n",
    "    return ' '.join(palavras_filtradas)\n",
    "\n",
    "def remover_urls(texto):\n",
    "    # Remove todos os urls que começam com 'www', 'https' e 'http'\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', texto, flags=re.MULTILINE)\n",
    "\n",
    "def remover_contracoes(texto):\n",
    "    return contractions.fix(texto)\n",
    "\n",
    "def lematizar(texto):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(texto)\n",
    "    # Reduzir as palavras e retornar a lista de palavras reduzidas\n",
    "    return ' '.join(lemmatizer.lemmatize(w) for w in words)\n",
    "\n",
    "\n",
    "# Carrega os dados\n",
    "sms = pd.read_csv('SMSSpamCollection', delimiter='\\t', header=None, names=['Label', 'Mensagem'])\n",
    "\n",
    "# Discretiza os labels\n",
    "sms['Label'] = sms['Label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Cria uma nova coluna com texto em minúsculas\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem'].str.lower()\n",
    "\n",
    "# Remove tudo que não é letra minúscula\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem_Preprocessada'].apply(remover_caracteres_especiais)\n",
    "\n",
    "# Inicializa as stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Aplica as funções de pré-processamento\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem_Preprocessada'].apply(remover_stopwords, args=(stop_words,))\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem_Preprocessada'].apply(remover_contracoes)\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem_Preprocessada'].apply(lematizar)\n",
    "sms['Mensagem_Preprocessada'] = sms['Mensagem_Preprocessada'].apply(remover_urls)\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame resultante\n",
    "print(sms.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar a tabela tf-idf sem vazar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(sms['Mensagem_Preprocessada'], sms['Label'], stratify=sms['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar o vetor TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Ajustar e transformar os dados\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search - diferentes modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X = sms['Mensagem_Preprocessada']\n",
    "y = sms['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Criar um pipeline com TfidfVectorizer e KNeighborsClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Definir os hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [1, 3, 5, 7, 9, 11, 15],\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='f1_macro', cv=5, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Hiperparâmetros: {'knn__metric': 'euclidean', 'knn__n_neighbors': 1, 'knn__weights': 'uniform'}\n",
      "Acurácia: 0.947085201793722\n",
      "F1 Macro: 0.8666346354625976\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ajustar o GridSearch aos dados\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Obter os melhores hiperparâmetros\n",
    "print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Fazer previsões com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Ajustar o modelo com os melhores parâmetros\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Acurácia:\", acuracia)\n",
    "print(\"F1 Macro:\", f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC  \n",
    "\n",
    "\n",
    "# Criar um pipeline com TfidfVectorizer e SVC\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Definir os hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__kernel': ['linear', 'rbf'],\n",
    "    'svm__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='f1_macro', cv=5, n_jobs=-1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Hiperparâmetros: {'svm__C': 1, 'svm__gamma': 'scale', 'svm__kernel': 'linear'}\n",
      "Acurácia: 0.979372197309417\n",
      "F1 Macro: 0.953174271320816\n"
     ]
    }
   ],
   "source": [
    "# Ajustar o GridSearch aos dados\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Obter os melhores hiperparâmetros\n",
    "print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Fazer previsões com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Ajustar o modelo com os melhores parâmetros\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Acurácia:\", acuracia)\n",
    "print(\"F1 Macro:\", f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Criar um pipeline com TfidfVectorizer e DecisionTreeClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Definir os hiperparâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [None, 10, 20, 30],\n",
    "    'dt__min_samples_split': [2, 5, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, \n",
    "                           scoring='f1_macro', cv=5, n_jobs=-1, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores Hiperparâmetros: {'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 5}\n",
      "Acurácia: 0.9497757847533632\n",
      "F1 Macro: 0.8890152861713473\n"
     ]
    }
   ],
   "source": [
    "# Ajustar o GridSearch aos dados\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Obter os melhores hiperparâmetros\n",
    "print(\"Melhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Fazer previsões com os melhores parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Ajustar o modelo com os melhores parâmetros\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Acurácia:\", acuracia)\n",
    "print(\"F1 Macro:\", f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média F1 Score SVM: 0.9564, Desvio Padrão: 0.0105\n",
      "Média F1 Score KNN: 0.8885, Desvio Padrão: 0.0161\n",
      "Média F1 Score Decision Tree: 0.9278, Desvio Padrão: 0.0174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# DataFrame com as colunas 'Mensagem' e 'Label'\n",
    "X = sms['Mensagem_Preprocessada']\n",
    "y = sms['Label']\n",
    "\n",
    "# Hiperparâmetros definidos\n",
    "best_params_svm = {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "best_params_knn = {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
    "best_params_tree = {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "f1_score_svm = []\n",
    "f1_score_knn = []\n",
    "f1_score_tree = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Separação manual dos conjuntos de treino e teste    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Vetorização desses conjuntos\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Ajustar e transformar os dados\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "    # Modelo SVM\n",
    "    model_svm = SVC(**best_params_svm)\n",
    "    model_svm.fit(X_train_vect, y_train)\n",
    "    y_pred_svm = model_svm.predict(X_test_vect)\n",
    "    f1_score_svm.append(f1_score(y_test, y_pred_svm, average='macro'))\n",
    "\n",
    "    # Modelo KNN\n",
    "    model_knn = KNeighborsClassifier(**best_params_knn)\n",
    "    model_knn.fit(X_train_vect, y_train)\n",
    "    y_pred_knn = model_knn.predict(X_test_vect)\n",
    "    f1_score_knn.append(f1_score(y_test, y_pred_knn, average='macro'))\n",
    "\n",
    "    # Modelo Decision Tree\n",
    "    model_tree = DecisionTreeClassifier(**best_params_tree)\n",
    "    model_tree.fit(X_train_vect, y_train)\n",
    "    y_pred_tree = model_tree.predict(X_test_vect)\n",
    "    f1_score_tree.append(f1_score(y_test, y_pred_tree, average='macro'))\n",
    "\n",
    "# Convertendo listas para arrays NumPy\n",
    "f1_score_svm = np.array(f1_score_svm)\n",
    "f1_score_knn = np.array(f1_score_knn)\n",
    "f1_score_tree = np.array(f1_score_tree)\n",
    "\n",
    "# Cálculo da média e do desvio padrão dos F1 scores\n",
    "mean_f1_svm = np.mean(f1_score_svm)\n",
    "std_f1_svm = np.std(f1_score_svm)\n",
    "\n",
    "mean_f1_knn = np.mean(f1_score_knn)\n",
    "std_f1_knn = np.std(f1_score_knn)\n",
    "\n",
    "mean_f1_tree = np.mean(f1_score_tree)\n",
    "std_f1_tree = np.std(f1_score_tree)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Média F1 Score SVM: {mean_f1_svm:.4f}, Desvio Padrão: {std_f1_svm:.4f}\")\n",
    "print(f\"Média F1 Score KNN: {mean_f1_knn:.4f}, Desvio Padrão: {std_f1_knn:.4f}\")\n",
    "print(f\"Média F1 Score Decision Tree: {mean_f1_tree:.4f}, Desvio Padrão: {std_f1_tree:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codigo do Fonseca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resultados-undersampling-llm/out-gui-padraonovo/llama3.1/luxury_beauty_2L/out.fold=0.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m saidaH[pasta] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUMFOLD):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdirCls\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/out.fold=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfold\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m arquivo:\n\u001b[1;32m     29\u001b[0m         dados \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(arquivo)\n\u001b[1;32m     31\u001b[0m         saidaH[pasta]\u001b[38;5;241m.\u001b[39mappend(dados[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resultados-undersampling-llm/out-gui-padraonovo/llama3.1/luxury_beauty_2L/out.fold=0.json'"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import itertools\n",
    "\n",
    "# dataset = \"sentistrength_twitter_2L\"\n",
    "# dataset = \"vader_amazon_2L\"\n",
    "dataset = \"luxury_beauty_2L\"\n",
    "# dataset = \"digital_music_2L\"\n",
    "\n",
    "pastas = [\n",
    "          'padraonovo',\n",
    "          'rr_02',\n",
    "          'e2sc_RL',\n",
    "        #   'cnn',\n",
    "          'nearmiss_1',\n",
    "          'nearmiss_2',\n",
    "         ]\n",
    "\n",
    "saidaH = {}\n",
    "for pasta in pastas:\n",
    "    dirCls = f\"resultados-undersampling-llm/out-gui-{pasta}/llama3.1/{dataset}\"\n",
    "\n",
    "    NUMFOLD = 10\n",
    "    if dataset  in [\"luxury_beauty_2L\", \"digital_music_2L\"]:\n",
    "        NUMFOLD = 5\n",
    "\n",
    "    saidaH[pasta] = []\n",
    "    for fold in range(NUMFOLD):\n",
    "        with open(f\"{dirCls}/out.fold={fold}.json\", 'r') as arquivo:\n",
    "            dados = json.load(arquivo)\n",
    "\n",
    "            saidaH[pasta].append(dados[\"macro\"])\n",
    "\n",
    "saidaH_teste = []\n",
    "\n",
    "pares = list(itertools.combinations(saidaH.keys(), 2))\n",
    "\n",
    "# Número de testes realizados (correção de Bonferroni)\n",
    "n_testes = len(pares)\n",
    "\n",
    "for metodo_a, metodo_b in pares:\n",
    "    valores_a = saidaH[metodo_a]\n",
    "    valores_b = saidaH[metodo_b]\n",
    "    \n",
    "    # Teste t\n",
    "    t_stat, p_val = stats.ttest_ind(valores_a, valores_b)\n",
    "    \n",
    "    # Correção de Bonferroni\n",
    "    p_val_corrigido = p_val * n_testes\n",
    "    \n",
    "    if p_val_corrigido < 0.05:\n",
    "        comparacao = \"estatisticamente diferente\"\n",
    "    else:\n",
    "        comparacao = \"não estatisticamente diferente\"\n",
    "    \n",
    "    saidaH_teste.append({\n",
    "        'metodo_a': metodo_a,\n",
    "        'metodo_b': metodo_b,\n",
    "        'comparacao': comparacao\n",
    "    })\n",
    "\n",
    "\n",
    "print(f\"{dataset}\")\n",
    "for resultado in saidaH_teste:\n",
    "    if resultado['metodo_a'] != 'padraonovo': break\n",
    "    print(f\"Método A: {resultado['metodo_a']}, Método B: {resultado['metodo_b']}\")\n",
    "    print(f\"Comparação: {resultado['comparacao']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meu código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média F1 Score SVM: 0.9564, Desvio Padrão: 0.0105\n",
      "Média F1 Score KNN: 0.8885, Desvio Padrão: 0.0161\n",
      "Média F1 Score Decision Tree: 0.9192, Desvio Padrão: 0.0158\n",
      "Método A: SVM, Método B: KNN\n",
      "Comparação: estatisticamente diferente, Estatística t: 10.6058, p-valor corrigido: 0.0000\n",
      "--------------------------------------------------\n",
      "Método A: SVM, Método B: Decision Tree\n",
      "Comparação: estatisticamente diferente, Estatística t: 5.8769, p-valor corrigido: 0.0000\n",
      "--------------------------------------------------\n",
      "Método A: KNN, Método B: Decision Tree\n",
      "Comparação: estatisticamente diferente, Estatística t: -4.0832, p-valor corrigido: 0.0021\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "\n",
    "# DataFrame com as colunas 'Mensagem' e 'Label'\n",
    "X = sms['Mensagem_Preprocessada']\n",
    "y = sms['Label']\n",
    "\n",
    "# Hiperparâmetros definidos\n",
    "best_params_svm = {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "best_params_knn = {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
    "best_params_tree = {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "# Dicionário para armazenar F1 scores\n",
    "f1_scores = {\n",
    "    'SVM': [],\n",
    "    'KNN': [],\n",
    "    'Decision Tree': []\n",
    "}\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Separação manual dos conjuntos de treino e teste    \n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Vetorização desses conjuntos\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    \n",
    "    # Ajustar e transformar os dados\n",
    "    X_train_vect = vectorizer.fit_transform(X_train)\n",
    "    X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "    # Modelo SVM\n",
    "    model_svm = SVC(**best_params_svm)\n",
    "    model_svm.fit(X_train_vect, y_train)\n",
    "    y_pred_svm = model_svm.predict(X_test_vect)\n",
    "    f1_scores['SVM'].append(f1_score(y_test, y_pred_svm, average='macro'))\n",
    "\n",
    "    # Modelo KNN\n",
    "    model_knn = KNeighborsClassifier(**best_params_knn)\n",
    "    model_knn.fit(X_train_vect, y_train)\n",
    "    y_pred_knn = model_knn.predict(X_test_vect)\n",
    "    f1_scores['KNN'].append(f1_score(y_test, y_pred_knn, average='macro'))\n",
    "\n",
    "    # Modelo Decision Tree\n",
    "    model_tree = DecisionTreeClassifier(**best_params_tree)\n",
    "    model_tree.fit(X_train_vect, y_train)\n",
    "    y_pred_tree = model_tree.predict(X_test_vect)\n",
    "    f1_scores['Decision Tree'].append(f1_score(y_test, y_pred_tree, average='macro'))\n",
    "\n",
    "\n",
    "# Convertendo listas para arrays NumPy\n",
    "f1_score_svm = np.array(f1_scores['SVM'])\n",
    "f1_score_knn = np.array(f1_scores['KNN'])\n",
    "f1_score_tree = np.array(f1_scores['Decision Tree'])\n",
    "\n",
    "# Cálculo da média e do desvio padrão dos F1 scores\n",
    "mean_f1_svm = np.mean(f1_score_svm)\n",
    "std_f1_svm = np.std(f1_score_svm)\n",
    "\n",
    "mean_f1_knn = np.mean(f1_score_knn)\n",
    "std_f1_knn = np.std(f1_score_knn)\n",
    "\n",
    "mean_f1_tree = np.mean(f1_score_tree)\n",
    "std_f1_tree = np.std(f1_score_tree)\n",
    "\n",
    "# Resultados\n",
    "print(f\"Média F1 Score SVM: {mean_f1_svm:.4f}, Desvio Padrão: {std_f1_svm:.4f}\")\n",
    "print(f\"Média F1 Score KNN: {mean_f1_knn:.4f}, Desvio Padrão: {std_f1_knn:.4f}\")\n",
    "print(f\"Média F1 Score Decision Tree: {mean_f1_tree:.4f}, Desvio Padrão: {std_f1_tree:.4f}\")\n",
    "\n",
    "# Comparação estatística usando teste t\n",
    "saidaH_teste = []\n",
    "pares = list(itertools.combinations(['SVM', 'KNN', 'Decision Tree'], 2))\n",
    "n_testes = len(pares)\n",
    "\n",
    "for metodo_a, metodo_b in pares:\n",
    "    valores_a = f1_scores[metodo_a]\n",
    "    valores_b = f1_scores[metodo_b]\n",
    "    \n",
    "    # Teste t\n",
    "    t_stat, p_val = stats.ttest_ind(valores_a, valores_b)\n",
    "    \n",
    "    # Correção de Bonferroni\n",
    "    p_val_corrigido = p_val * n_testes\n",
    "    \n",
    "    if p_val_corrigido < 0.05:\n",
    "        comparacao = \"estatisticamente diferente\"\n",
    "    else:\n",
    "        comparacao = \"não estatisticamente diferente\"\n",
    "    \n",
    "    saidaH_teste.append({\n",
    "        'metodo_a': metodo_a,\n",
    "        'metodo_b': metodo_b,\n",
    "        'comparacao': comparacao,\n",
    "        't_stat': t_stat,\n",
    "        'p_val': p_val_corrigido\n",
    "    })\n",
    "\n",
    "# Exibir resultados do teste t\n",
    "for resultado in saidaH_teste:\n",
    "    print(f\"Método A: {resultado['metodo_a']}, Método B: {resultado['metodo_b']}\")\n",
    "    print(f\"Comparação: {resultado['comparacao']}, Estatística t: {resultado['t_stat']:.4f}, p-valor corrigido: {resultado['p_val']:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bibliotecas\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar as mensagens\n",
    "sms['Tokens'] = sms['Mensagem_Preprocessada'].apply(lambda x: x.split())\n",
    "\n",
    "# Treinar o modelo Word2Vec\n",
    "modelo_w2v = Word2Vec(sentences=sms['Tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Salvar o modelo se desejar\n",
    "# modelo_w2v.save(\"modelo_w2v.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.vector_size)\n",
    "\n",
    "# Criar vetores de sentença\n",
    "sms['Mensagem_Vector'] = sms['Mensagem_Preprocessada'].apply(lambda x: get_sentence_vector(x, modelo_w2v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Acurácia: 0.9291479820627803\n",
      "KNN - F1 Macro: 0.856995816293564\n",
      "SVM - Acurácia: 0.8663677130044843\n",
      "SVM - F1 Macro: 0.46419990389235943\n",
      "Decision Tree - Acurácia: 0.9327354260089686\n",
      "Decision Tree - F1 Macro: 0.8591196939296382\n"
     ]
    }
   ],
   "source": [
    "# Transformar em array\n",
    "X = np.array(list(sms['Mensagem_Vector']))\n",
    "y = sms['Label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Hiperparâmetros definidos\n",
    "best_params_svm = {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "best_params_knn = {'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'uniform'}\n",
    "best_params_tree = {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
    "\n",
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier(**best_params_knn)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(**best_params_svm)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(**best_params_tree)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Avaliação do KNN\n",
    "acuracia_knn = accuracy_score(y_test, y_pred_knn)\n",
    "f1_macro_knn = f1_score(y_test, y_pred_knn, average='macro')\n",
    "print(\"KNN - Acurácia:\", acuracia_knn)\n",
    "print(\"KNN - F1 Macro:\", f1_macro_knn)\n",
    "\n",
    "# Avaliação do SVM\n",
    "acuracia_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_macro_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "print(\"SVM - Acurácia:\", acuracia_svm)\n",
    "print(\"SVM - F1 Macro:\", f1_macro_svm)\n",
    "\n",
    "# Avaliação da Decision Tree\n",
    "acuracia_tree = accuracy_score(y_test, y_pred_tree)\n",
    "f1_macro_tree = f1_score(y_test, y_pred_tree, average='macro')\n",
    "print(\"Decision Tree - Acurácia:\", acuracia_tree)\n",
    "print(\"Decision Tree - F1 Macro:\", f1_macro_tree)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelo FastTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  1568\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   65216 lr:  0.000000 avg.loss:  2.840988 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Criar um arquivo temporário para o FastText\n",
    "with open('temp_fasttext.txt', 'w') as f:\n",
    "    for mensagem in sms['Mensagem_Preprocessada']:\n",
    "        f.write(mensagem + '\\n')\n",
    "\n",
    "# Treinar o modelo FastText\n",
    "modelo_fasttext = fasttext.train_unsupervised('temp_fasttext.txt', model='skipgram')\n",
    "\n",
    "# Remover o arquivo temporário se não for mais necessário\n",
    "import os\n",
    "os.remove('temp_fasttext.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Acurácia: 0.9515695067264573\n",
      "KNN - F1 Macro: 0.8993843747493382\n",
      "SVM - Acurácia: 0.9443946188340807\n",
      "SVM - F1 Macro: 0.8632020959979736\n",
      "Decision Tree - Acurácia: 0.9533632286995516\n",
      "Decision Tree - F1 Macro: 0.8998618307426598\n"
     ]
    }
   ],
   "source": [
    "def get_sentence_vector_fasttext(sentence, model):\n",
    "    words = sentence.split()\n",
    "    word_vectors = [model.get_word_vector(word) for word in words if word in model.get_words()]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.get_dimension())\n",
    "\n",
    "# Criar vetores de sentença\n",
    "sms['Mensagem_Vector'] = sms['Mensagem_Preprocessada'].apply(lambda x: get_sentence_vector_fasttext(x, modelo_fasttext))\n",
    "\n",
    "X = np.array(list(sms['Mensagem_Vector']))\n",
    "y = sms['Label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# KNN\n",
    "knn_model = KNeighborsClassifier(**best_params_knn)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(**best_params_svm)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(**best_params_tree)\n",
    "tree_model.fit(X_train, y_train)\n",
    "y_pred_tree = tree_model.predict(X_test)\n",
    "\n",
    "# Avaliação do KNN\n",
    "acuracia_knn = accuracy_score(y_test, y_pred_knn)\n",
    "f1_macro_knn = f1_score(y_test, y_pred_knn, average='macro')\n",
    "print(\"KNN - Acurácia:\", acuracia_knn)\n",
    "print(\"KNN - F1 Macro:\", f1_macro_knn)\n",
    "\n",
    "# Avaliação do SVM\n",
    "acuracia_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_macro_svm = f1_score(y_test, y_pred_svm, average='macro')\n",
    "print(\"SVM - Acurácia:\", acuracia_svm)\n",
    "print(\"SVM - F1 Macro:\", f1_macro_svm)\n",
    "\n",
    "# Avaliação da Decision Tree\n",
    "acuracia_tree = accuracy_score(y_test, y_pred_tree)\n",
    "f1_macro_tree = f1_score(y_test, y_pred_tree, average='macro')\n",
    "print(\"Decision Tree - Acurácia:\", acuracia_tree)\n",
    "print(\"Decision Tree - F1 Macro:\", f1_macro_tree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
